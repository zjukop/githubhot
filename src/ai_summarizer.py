"""AI Summarizer using OpenAI-compatible LLM APIs."""

import json
import re
from dataclasses import dataclass, field

from loguru import logger
from openai import OpenAI
from tenacity import (
    retry,
    retry_if_exception_type,
    stop_after_attempt,
    wait_exponential,
)

from .config import get_settings
from .crawler import Repository

# Maximum characters to send from README to LLM
MAX_README_CHARS = 2000


SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯åšä¸»å’Œå¼€æºé¡¹ç›®åˆ†æžå¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æž GitHub é¡¹ç›®å¹¶ç”Ÿæˆç®€æ´ã€æœ‰æ´žå¯ŸåŠ›çš„ä¸­æ–‡æ€»ç»“ã€‚

åˆ†æžæ—¶è¯·å…³æ³¨ï¼š
1. é¡¹ç›®è§£å†³äº†ä»€ä¹ˆæ ¸å¿ƒé—®é¢˜
2. æŠ€æœ¯äº®ç‚¹å’Œåˆ›æ–°ç‚¹
3. ç›®æ ‡ç”¨æˆ·ç¾¤ä½“
4. é¡¹ç›®æˆç†Ÿåº¦å’Œæ´»è·ƒåº¦

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¿”å›žï¼ˆä¸è¦åŒ…å« markdown ä»£ç å—æ ‡è®°ï¼‰ï¼š
{
    "one_liner_cn": "ä¸€å¥è¯ä¸­æ–‡ä»‹ç»ï¼ˆ20å­—ä»¥å†…ï¼Œä¿çš®æ˜“æ‡‚ï¼Œå¯ç”¨emojiï¼‰",
    "core_features": [
        "æ ¸å¿ƒåŠŸèƒ½1",
        "æ ¸å¿ƒåŠŸèƒ½2",
        "æ ¸å¿ƒåŠŸèƒ½3"
    ],
    "use_case": "é€‚åˆä»€ä¹ˆäººç”¨ï¼Ÿè§£å†³äº†ä»€ä¹ˆç—›ç‚¹ï¼Ÿï¼ˆ50å­—ä»¥å†…ï¼‰",
    "score": 4,
    "score_reason": "è¯„åˆ†ç†ç”±ï¼ˆ20å­—ä»¥å†…ï¼‰"
}

è¯„åˆ†æ ‡å‡†ï¼ˆscore 1-5ï¼‰ï¼š
- 5æ˜Ÿï¼šé©å‘½æ€§é¡¹ç›®ï¼Œå¼ºçƒˆæŽ¨è
- 4æ˜Ÿï¼šä¼˜ç§€é¡¹ç›®ï¼Œå€¼å¾—å…³æ³¨
- 3æ˜Ÿï¼šä¸é”™çš„é¡¹ç›®ï¼Œç‰¹å®šåœºæ™¯æœ‰ç”¨
- 2æ˜Ÿï¼šä¸€èˆ¬é¡¹ç›®ï¼Œå¯ä»¥äº†è§£
- 1æ˜Ÿï¼šæ—©æœŸé¡¹ç›®æˆ–å°ä¼—å·¥å…·"""


USER_PROMPT_TEMPLATE = """è¯·åˆ†æžä»¥ä¸‹ GitHub é¡¹ç›®ï¼š

**é¡¹ç›®åç§°**: {name}
**GitHub åœ°å€**: {url}
**æè¿°**: {description}
**ç¼–ç¨‹è¯­è¨€**: {language}
**Star æ•°**: {stars:,}
**ä»Šæ—¥ Star**: {stars_today}

**README å†…å®¹ï¼ˆæˆªå–ï¼‰**:
```
{readme_truncated}
```

è¯·ç”¨ä¸­æ–‡åˆ†æžè¿™ä¸ªé¡¹ç›®ï¼Œè¿”å›žè§„å®šçš„ JSON æ ¼å¼ã€‚"""


@dataclass
class ProjectSummary:
    """AI-generated summary for a repository."""

    repo: Repository
    one_liner_cn: str = ""
    core_features: list[str] = field(default_factory=list)
    use_case: str = ""
    score: int = 3
    score_reason: str = ""
    is_top_pick: bool = False
    error: str | None = None

    def to_markdown(self) -> str:
        """Convert summary to markdown format."""
        stars_badge = "â­" * self.score
        top_badge = "ðŸ† **ä»Šæ—¥ç²¾é€‰**" if self.is_top_pick else ""

        features_md = "\n".join(f"  - {f}" for f in self.core_features)

        return f"""### [{self.repo.name}]({self.repo.url}) {top_badge}

> {self.one_liner_cn}

- **è¯­è¨€**: {self.repo.language} | **Stars**: {self.repo.stars:,} | **ä»Šæ—¥**: +{self.repo.stars_today}
- **æŽ¨èæŒ‡æ•°**: {stars_badge} ({self.score}/5) - {self.score_reason}

**æ ¸å¿ƒåŠŸèƒ½**:
{features_md}

**é€‚ç”¨åœºæ™¯**: {self.use_case}

---
"""


@dataclass
class SummaryResult:
    """Result of AI summarization."""

    top_picks: list[ProjectSummary] = field(default_factory=list)
    quick_looks: list[ProjectSummary] = field(default_factory=list)

    @property
    def all_summaries(self) -> list[ProjectSummary]:
        return self.top_picks + self.quick_looks


class AISummarizer:
    """Summarize GitHub repos using LLM."""

    def __init__(self):
        self.settings = get_settings()
        self.client = OpenAI(
            api_key=self.settings.openai_api_key.get_secret_value(),
            base_url=self.settings.openai_base_url,
        )

    def _truncate_readme(self, content: str) -> str:
        """Truncate README content to save tokens."""
        if not content:
            return "(README å†…å®¹ä¸ºç©º)"

        # Remove images and links to save tokens
        content = re.sub(r"!\[.*?\]\(.*?\)", "", content)
        content = re.sub(r"<img[^>]*>", "", content)

        # Keep first N characters
        if len(content) > MAX_README_CHARS:
            content = content[:MAX_README_CHARS] + "\n... (å†…å®¹å·²æˆªæ–­)"

        return content.strip() or "(README å†…å®¹ä¸ºç©º)"

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((Exception,)),
        before_sleep=lambda rs: logger.warning(f"LLM retry attempt {rs.attempt_number}"),
    )
    def _call_llm(self, repo: Repository) -> dict:
        """Call LLM API to get project summary."""
        user_prompt = USER_PROMPT_TEMPLATE.format(
            name=repo.name,
            url=repo.url,
            description=repo.description or "æ— æè¿°",
            language=repo.language,
            stars=repo.stars,
            stars_today=repo.stars_today or "N/A",
            readme_truncated=self._truncate_readme(repo.readme_content),
        )

        response = self.client.chat.completions.create(
            model=self.settings.llm_model,
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": user_prompt},
            ],
            temperature=0.7,
            max_tokens=500,
        )

        content = response.choices[0].message.content.strip()

        # Clean up response (remove markdown code blocks if present)
        if content.startswith("```"):
            content = re.sub(r"^```(?:json)?\n?", "", content)
            content = re.sub(r"\n?```$", "", content)

        return json.loads(content)

    def summarize_repo(self, repo: Repository) -> ProjectSummary:
        """Generate summary for a single repository."""
        summary = ProjectSummary(repo=repo)

        try:
            data = self._call_llm(repo)

            summary.one_liner_cn = data.get("one_liner_cn", "")
            summary.core_features = data.get("core_features", [])[:3]
            summary.use_case = data.get("use_case", "")
            summary.score = min(5, max(1, int(data.get("score", 3))))
            summary.score_reason = data.get("score_reason", "")

        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse LLM response for {repo.name}: {e}")
            summary.error = f"JSON parse error: {e}"
            summary.one_liner_cn = repo.description or "è§£æžå¤±è´¥"
            summary.core_features = ["è§£æžå¤±è´¥ï¼Œè¯·æŸ¥çœ‹åŽŸé¡¹ç›®"]

        except Exception as e:
            logger.error(f"LLM call failed for {repo.name}: {e}")
            summary.error = str(e)
            summary.one_liner_cn = repo.description or "API è°ƒç”¨å¤±è´¥"
            summary.core_features = ["API è°ƒç”¨å¤±è´¥ï¼Œè¯·ç¨åŽé‡è¯•"]

        return summary

    def summarize_all(self, repos: list[Repository]) -> SummaryResult:
        """
        Summarize all repositories and categorize into top picks and quick looks.

        Selection logic for top picks:
        1. Top N from trending list (by position)
        2. OR highest stars_today growth
        """
        result = SummaryResult()

        if not repos:
            logger.warning("No repositories to summarize")
            return result

        # Determine top picks
        # Strategy: Use stars_today if available, otherwise use list position
        repos_with_growth = [r for r in repos if r.stars_today > 0]

        if repos_with_growth:
            # Sort by stars growth today
            sorted_repos = sorted(repos_with_growth, key=lambda r: r.stars_today, reverse=True)
            top_pick_repos = set(r.name for r in sorted_repos[: self.settings.top_pick_count])
        else:
            # Fall back to list position (trending order)
            top_pick_repos = set(r.name for r in repos[: self.settings.top_pick_count])

        # Generate summaries
        for i, repo in enumerate(repos):
            logger.info(f"[{i + 1}/{len(repos)}] Summarizing {repo.name}...")
            summary = self.summarize_repo(repo)
            summary.is_top_pick = repo.name in top_pick_repos

            if summary.is_top_pick:
                result.top_picks.append(summary)
            else:
                result.quick_looks.append(summary)

        # Sort top picks by score
        result.top_picks.sort(key=lambda s: (s.score, s.repo.stars_today), reverse=True)

        return result


def summarize_repos(repos: list[Repository]) -> SummaryResult:
    """Convenience function to summarize repositories."""
    summarizer = AISummarizer()
    return summarizer.summarize_all(repos)
